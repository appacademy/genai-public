import time
import random
from typing import Dict, Any


class MockLLMService:
    """Mock service for when Ollama is not available."""

    def __init__(self):
        self.sample_responses = {
            "SQL Optimizer": [
                """1. Issue: Using SELECT *
   Problem: Retrieving all columns increases I/O and network transfer.
   Solution: Select only the necessary columns explicitly.

2. Issue: Missing indexes on join columns
   Problem: Joins on non-indexed columns can severely impact performance.
   Solution: Add indexes on the columns used in JOIN conditions (product_id, order_id).

3. Issue: Missing index on filter column
   Problem: The WHERE clause on customer_id is not using an index.
   Solution: Add an index on the customer_id column.
""",
                """1. Issue: Using COUNT(*)
   Problem: Counting all rows requires scanning the entire table.
   Solution: Use a more targeted counting approach or consider indexed columns.

2. Issue: Function in WHERE clause
   Problem: Using DATE_SUB() prevents efficient use of indexes.
   Solution: Pre-calculate the date value and use a direct comparison.

3. Issue: Missing composite index
   Problem: Multiple filter conditions without a suitable index.
   Solution: Create a composite index on (last_login, account_status).
""",
            ],
            "Summarizer": [
                """Climate change is a long-term shift in temperature and weather patterns affecting both specific locations and the entire planet. It disrupts traditional weather patterns, making them less predictable, which poses significant challenges for agriculture as farmers can no longer rely on expected temperature and rainfall levels. Research has linked climate change to increasingly frequent and intense extreme weather events, including hurricanes, floods, downpours, and winter storms.""",
                """Machine learning is a branch of artificial intelligence focused on using data and algorithms to simulate human learning processes, continuously improving accuracy over time. IBM has been instrumental in the field's development, with Arthur Samuel, an IBM researcher, coining the term "machine learning" during his work on a checkers-playing program. A significant early milestone occurred in 1962 when Robert Nealey, a checkers expert, lost to an IBM 7094 computer running Samuel's programâ€”an achievement that, while seemingly modest by today's standards, represented a breakthrough in artificial intelligence.""",
            ],
        }

    def generate(
        self,
        prompt: str,
        model: str = "mock-model",
        temperature: float = 0.7,
        max_tokens: int = 2048,
    ) -> Dict[str, Any]:
        """Generate a mock response based on the prompt."""
        start_time = time.time()
        response_text = self._get_response_for_prompt(prompt)

        # Add realistic delay
        time.sleep(random.uniform(0.5, 2.0))

        return {
            "response": response_text,
            "response_time": time.time() - start_time,
            "estimated_prompt_tokens": self._estimate_tokens(prompt),
            "estimated_completion_tokens": self._estimate_tokens(response_text),
            "estimated_total_tokens": self._estimate_tokens(prompt)
            + self._estimate_tokens(response_text),
        }

    def _get_response_for_prompt(self, prompt: str) -> str:
        """Select an appropriate response based on the prompt content."""
        if "SQL" in prompt or "query" in prompt:
            return random.choice(self.sample_responses["SQL Optimizer"])
        elif "summarize" in prompt or "summary" in prompt:
            return random.choice(self.sample_responses["Summarizer"])
        else:
            return "This is a mock response. In a real implementation, this would be generated by an actual LLM service like Ollama."

    def _estimate_tokens(self, text: str) -> int:
        """Estimate token count based on text length."""
        # Rough estimate: ~4 characters per token for English text
        return len(text) // 4
